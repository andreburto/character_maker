def llm_debug(prompt, response):
    print(f"PROMPT: {prompt}\nRESPONSE: {response}\n")
